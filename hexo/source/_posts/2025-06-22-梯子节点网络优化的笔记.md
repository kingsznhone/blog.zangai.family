---
title: 梯子节点网络优化的笔记
date: 2025-06-22 06:18:29
tags:
    - Utility
cover: /img/2025-06-22/cover.png
---

# 一代目

自建梯子差不多已经有8个年头了，

那年创世纪的SS横空出世，因为效果过于强悍，一时之间官方拿不出应对策略，作者被喝茶，协议逐渐被墙攻破并阻断

# 二代目

高墙阻挡不了好奇者探索整个世界的欲望，于是社区开始魔改SS，设计出更强悍的加密，使得SSR成为了最出名的第二代梯子，继续肩负起翻越高墙的重任

二代协议，始终是基于SS哲学的协议，即重视加密，使用强悍的密码学，确保使用者的隐私安全与信息安全不被窥探。

在技术手段落后的年代，在互联网还不普及的年代，信息的阻断，只需要少量的VPN协议阻断，DNS污染，IP域名拉黑

墙的意图，我想不是彻底关闭世界之窗，而是有选择性的展示一些无害的东西。

TLS普及之前，明文传输时时刻刻暴露着使用者的隐私，使得睁一只眼闭一只眼的状态能获取到超额的收益。

但是这一切随着TLS普及和SS的出现，平衡被打破了，隐私信息不再能够被截取，怎么办？筑墙！

既然无法再获取到明文信息，那么就解决协议本身，SS协议就像一台奔驰在高速上的公交车，用报纸壳壳把车玻璃全都遮起来了

那么从主干网上监测到SS协议并定向阻断，是一件轻而易举的事情。

几年的攻防战下来，基于SS的魔改协议流量特征过于明显，生存空间被挤压到极致，

在流量特征匹配的攻击下，服务器基本上露头就秒，就算再魔改也无济于事

那么，到此为止了吗？

# 三代目

社区中一个新项目逐渐获得关注，V2Ray首先提出了混淆的哲学，将代理流量藏在TLS流量中，便隐身在无数正常流量中。

Vmess协议依然受到了SS哲学的影响，是一个自研的加密层，而V2在使用中都会套一层TLS，服务器资源被双重加密白白浪费了。

攻防再一次升级，当梯子的流量不再具有显著特征，便再也无法定向爆破节点服务器，就只能基于一些旁路特征进行模糊阻断

V2开启了一个新的时代，经受住了历史的考验，在SSR被屠杀的血雨腥风中屹立不倒。

我的第一个自建梯子，就使用了当时最新提出的wss通道

记得在当时的社区理念和攻防烈度下，这个方案被认为是浪费资源，并且性能也不够理想

但这个方案但是胜在稳定，在猫鼠游戏的攻防下生存了很多年，一直陪伴我成长

V2的发展，随着2019年创始人的神秘消失，落下帷幕，社区进入了混乱阶段

# 四代目

社区用了很多年探索，到底什么样的梯子，才是终极解决方案

一个SS倒下了，千千万万个SS站起来了，无数技术者在自研协议的路上越走越远，而自研协议往往生命周期都不长。

终于有人洞察到了V2的混淆哲学，即将流量伪装成正常TLS连接，隐藏所有代理特征。

对于墙来说，彻底闭关锁国切断所有海底光缆连接，把自己变成朝鲜也是不可承受的代价

大隐隐于市，TLS作为国际通用的传输层标准，就是最好的混淆

这个哲学，直到近些年才逐渐开始被人认同

V2失去维护后，分裂出了Xray项目

Xray将混淆哲学用到了极致，开发了无加密Vless协议，TLS本身就带有加密，再多套一层加密是毫无意义的，释放了服务器的性能

并且随着攻防的不断升级，Xray居安思危，继续打磨自身，隐藏流量特征，开发出了TLS指纹伪造，Reality, Vision，解决了TLS in TLS的问题。

2024年底，经历无数磨练，无数分歧，无数实验，在战火中淬炼出的XHTTP协议

终极的解决方案，结束一切协议的协议。

# 优化

一个节点的速度，不仅要考虑物理带宽，也要做系统配置调优

不然空有千兆带宽，速度惨不忍睹，特别是跨洋的欧美节点，更需要精细化调整网络配置，以便在光速极限带来的绝对延迟下保持良好的收发性能



```
net.core.default_qdisc=fq
net.ipv4.tcp_congestion_control=bbr

net.core.rmem_max = 536870912  
net.core.wmem_max = 536870912

net.ipv4.tcp_rmem = 33554432 134217728 536870912
net.ipv4.tcp_wmem = 33554432 134217728 536870912
net.ipv4.tcp_moderate_rcvbuf = 1  
net.ipv4.tcp_window_scaling = 1  
net.ipv4.tcp_adv_win_scale = 2  
net.ipv4.tcp_low_latency = 1
net.ipv4.tcp_recovery = 1  
net.ipv4.tcp_max_orphans=4096
net.ipv4.tcp_timestamps=1
net.ipv4.tcp_fastopen=1
```

将这些内容写入`/etc/sysctl.conf`的末尾，然后执行`sudo sysctl -p`就可以启用所有的优化

#### 开启BBR
```
net.core.default_qdisc=fq
net.ipv4.tcp_congestion_control=bbr
```

先进的TCP拥塞控制算法，对于欧美的高延迟服务器有神一般的效果

#### 缓冲区限制

```
net.core.rmem_max = 536870912  
net.core.wmem_max = 536870912
```
设置更大的缓冲区，梯子节点一般不会负担其他任务，适当调高缓冲区，可以在网络环境有波动的时候有更大的承载能力

#### 自动调整缓冲区

```
net.ipv4.tcp_rmem = 33554432 134217728 536870912
net.ipv4.tcp_wmem = 33554432 134217728 536870912
net.ipv4.tcp_moderate_rcvbuf = 1   
```

启用 TCP 接收缓冲区的自动调整功能。内核会根据网络条件动态调整接收缓冲区大小


#### 窗口缩放

```
net.ipv4.tcp_window_scaling = 1
```

启用 TCP 窗口缩放，允许 TCP 窗口大小超过 64KB。在高速网络环境下可以提高传输效率。

#### 广告窗口

```
net.ipv4.tcp_adv_win_scale = 2
```

控制 TCP 接收缓冲区中用于广告窗口的比例。默认值为 1 或 2，设为 2 表示内核会将接收缓冲区的 1/4 用于应用程序缓存（其余用于协议开销），从而优化吞吐量。

#### 低延迟模式

```
net.ipv4.tcp_low_latency = 1
```
启用低延迟模式，优先减少延迟而非提高吞吐量。适用于对延迟敏感的应用（如实时音视频、游戏等），但可能牺牲部分吞吐量。

#### 丢包恢复机制

```
net.ipv4.tcp_recovery = 1
```
启用 TCP 丢包恢复机制。通过更快的丢包检测和恢复，减少重传超时对性能的影响。

####  孤儿套接字

```
net.ipv4.tcp_max_orphans=4096
```
保护系统资源不被孤儿 TCP 连接耗尽，若服务器处理大量短连接，可能因客户端异常断开或未正确关闭连接，导致孤儿套接字堆积。


#### 关闭慢启动

```
net.ipv4.tcp_slow_start_after_idle=0
```
Linux 内核会在 TCP 连接空闲一段时间后，重新进入慢启动，导致传输速率降低。而设置为 0 可以避免这个问题，提高网络性能。

#### 启用时间戳

```
net.ipv4.tcp_timestamps=1
```

帮助系统更精确计算数据包往返时间，优化超时重传机制。

#### 快速连接

```
net.ipv4.tcp_fastopen=1
```
允许在首次 SYN 包中直接携带数据，服务端在完成握手前即可处理请求，省去 1 个 RTT 的等待时间。

#### 半连接队列长度

```
net.ipv4.tcp_max_syn_backlog=1024
```

高并发场景下确保队列容量足够，连接请求不被拒绝

